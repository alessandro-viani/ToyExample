{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from Posterior import Posterior\n",
    "from Util import creation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "create_data = False\n",
    "pm_run = True\n",
    "fb_run = True\n",
    "em_run = True\n",
    "\n",
    "n_file = 100\n",
    "n_data = 100\n",
    "\n",
    "cfg = {'n_particles': 100, 'theta_eff': None, 'sourcespace': None, 'data': None,\n",
    "       'n_bins': 50, 'sequence_evolution': None, 'method': None, 'verbose': False}\n",
    "\n",
    "theta_true = np.linspace(0.01, 0.1, n_file)\n",
    "\n",
    "err_map_mean_pm, err_map_theta_pm, err_pm_mean_pm, err_pm_theta_pm, cpu_time_pm, ess_pm = np.zeros((6, n_file))\n",
    "err_map_mean_fb, err_map_theta_fb, err_pm_mean_fb, err_pm_theta_fb, cpu_time_fb, ess_fb = np.zeros((6, n_file))\n",
    "err_map_mean_em, err_map_theta_em, err_pm_mean_em, err_pm_theta_em, cpu_time_em, ess_em = np.zeros((6, n_file))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DATA CREATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "if create_data:\n",
    "    for idx, _n in enumerate(theta_true):\n",
    "        sourcespace, data = creation_data(n_data=n_data, theta=_n)\n",
    "        with open(f'data/data_{idx}.pkl', 'wb') as f:\n",
    "            pickle.dump([sourcespace, data, _n], f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RUN PROP METHOD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 1 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ale/Documents/phd/toy_example/Particle.py:76: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  rapp_like = part_aux.like / self.like\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - 3 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ale/Documents/phd/toy_example/Particle.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rapp_like = part_aux.like / self.like\n",
      "/Users/ale/Documents/phd/toy_example/Particle.py:94: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rapp_like = part_aux.like / self.like\n",
      "/Users/ale/Documents/phd/toy_example/Particle.py:94: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  rapp_like = part_aux.like / self.like\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m cfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmethod\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEM\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     20\u001B[0m post_em \u001B[38;5;241m=\u001B[39m Posterior(cfg\u001B[38;5;241m=\u001B[39mcfg)\n\u001B[0;32m---> 21\u001B[0m post_em \u001B[38;5;241m=\u001B[39m \u001B[43mpost_em\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_smc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msol/sol_em_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     23\u001B[0m     pickle\u001B[38;5;241m.\u001B[39mdump(post_em, f)\n",
      "File \u001B[0;32m~/Documents/phd/toy_example/Posterior.py:221\u001B[0m, in \u001B[0;36mPosterior.perform_smc\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetropolis_hastings()\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexponent_like \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexponent_like, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevolution_exponent())\n\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimportance_sampling\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexponent_like\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresampling()\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvector_post()\n",
      "File \u001B[0;32m~/Documents/phd/toy_example/Posterior.py:110\u001B[0m, in \u001B[0;36mPosterior.importance_sampling\u001B[0;34m(self, next_alpha)\u001B[0m\n\u001B[1;32m    108\u001B[0m weight_u \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_particles)\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, _p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparticle):\n\u001B[0;32m--> 110\u001B[0m     new_like \u001B[38;5;241m=\u001B[39m \u001B[43mevaluation_likelihood\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_p\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_p\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtheta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msourcespace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_alpha\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _p\u001B[38;5;241m.\u001B[39mlike \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    112\u001B[0m         weight_upgrade \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/Documents/phd/toy_example/Particle.py:25\u001B[0m, in \u001B[0;36mevaluation_likelihood\u001B[0;34m(mean, theta, sourcespace, data, exponent_like)\u001B[0m\n\u001B[1;32m     23\u001B[0m     log_likelihood \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, _d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(data):\n\u001B[0;32m---> 25\u001B[0m         log_likelihood \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m log_normal(_d, np\u001B[38;5;241m.\u001B[39mexp(\u001B[43mlog_normal\u001B[49m\u001B[43m(\u001B[49m\u001B[43msourcespace\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m), theta)\n\u001B[1;32m     26\u001B[0m     likelihood \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(exponent_like \u001B[38;5;241m*\u001B[39m log_likelihood)\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m likelihood\n",
      "File \u001B[0;32m~/Documents/phd/toy_example/Util.py:8\u001B[0m, in \u001B[0;36mlog_normal\u001B[0;34m(x, mean, std)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_normal\u001B[39m(x, mean, std):\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39mlog(np\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mpi) \u001B[38;5;241m*\u001B[39m std) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msquare\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstd\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for idx, _n in enumerate(theta_true):\n",
    "    print(f'{idx} - ', end='')\n",
    "    cfg['theta_eff'] = 0.5 * _n\n",
    "    with open(f'data/data_{idx}.pkl', 'rb') as f:\n",
    "        cfg['sourcespace'], cfg['data'], useless = pickle.load(f)\n",
    "    if pm_run:\n",
    "        cfg['method'] = 'PM'\n",
    "        post_pm = Posterior(cfg=cfg)\n",
    "        post_pm = post_pm.perform_smc()\n",
    "        with open(f'sol/sol_pm_{idx}.pkl', 'wb') as f:\n",
    "            pickle.dump(post_pm, f)\n",
    "    if fb_run:\n",
    "        cfg['method'] = 'FB'\n",
    "        post_fb = Posterior(cfg=cfg)\n",
    "        post_fb = post_fb.perform_smc()\n",
    "        with open(f'sol/sol_fb_{idx}.pkl', 'wb') as f:\n",
    "            pickle.dump(post_fb, f)\n",
    "    if em_run:\n",
    "        cfg['method'] = 'EM'\n",
    "        post_em = Posterior(cfg=cfg)\n",
    "        post_em = post_em.perform_smc()\n",
    "        with open(f'sol/sol_em_{idx}.pkl', 'wb') as f:\n",
    "            pickle.dump(post_em, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ERRORS EVALUATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for idx, _n in enumerate(theta_true):\n",
    "    print(f'{idx} - ', end='')\n",
    "\n",
    "    with open(f'sol/sol_pm_{idx}.pkl', 'rb') as f:\n",
    "        post_pm = pickle.load(f)\n",
    "    with open(f'sol/sol_fb_{idx}.pkl', 'rb') as f:\n",
    "        post_fb = pickle.load(f)\n",
    "    with open(f'sol/sol_em_{idx}.pkl', 'rb') as f:\n",
    "        post_em = pickle.load(f)\n",
    "\n",
    "    err_map_mean_pm[idx] = (post_pm.map_mean - 0)\n",
    "    err_map_mean_fb[idx] = (post_fb.map_mean - 0)\n",
    "    err_map_mean_em[idx] = (post_em.map_mean - 0)\n",
    "\n",
    "    err_pm_mean_pm[idx] = (post_pm.pm_mean - 0)\n",
    "    err_pm_mean_fb[idx] = (post_fb.pm_mean - 0)\n",
    "    err_pm_mean_em[idx] = (post_em.pm_mean - 0)\n",
    "\n",
    "    err_map_theta_pm[idx] = (post_pm.map_theta - _n) / _n\n",
    "    err_map_theta_fb[idx] = (post_fb.map_theta - _n) / _n\n",
    "    err_map_theta_em[idx] = (post_em.map_theta - _n) / _n\n",
    "\n",
    "    err_pm_theta_pm[idx] = (post_pm.pm_theta - _n) / _n\n",
    "    err_pm_theta_fb[idx] = (post_fb.pm_theta - _n) / _n\n",
    "    err_pm_theta_em[idx] = (post_em.pm_theta - _n) / _n\n",
    "\n",
    "    cpu_time_pm[idx] = post_pm.cpu_time\n",
    "    cpu_time_fb[idx] = post_fb.cpu_time\n",
    "    cpu_time_em[idx] = post_em.cpu_time\n",
    "\n",
    "    ess_pm[idx] = post_pm.ess\n",
    "    ess_fb[idx] = post_fb.ess[-1]\n",
    "    ess_em[idx] = post_em.ess[-1]\n",
    "\n",
    "with open(f'sol/analytics.pkl', 'wb') as f:\n",
    "    pickle.dump([err_map_mean_pm, err_map_theta_pm, err_pm_mean_pm, err_pm_theta_pm,\n",
    "                 err_map_mean_fb, err_map_theta_fb, err_pm_mean_fb, err_pm_theta_fb,\n",
    "                 err_map_mean_em, err_map_theta_em, err_pm_mean_em, err_pm_theta_em,\n",
    "                 cpu_time_pm, cpu_time_fb, cpu_time_em, ess_pm, ess_fb, ess_em], f)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
